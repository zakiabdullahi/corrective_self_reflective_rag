<div align="center">

# ğŸ”® Corrective + Self-Reflective RAG

### *Advanced Retrieval-Augmented Generation with Adaptive Intelligence*

[![Python 3.12](https://img.shields.io/badge/python-3.12-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.115.6-009688.svg?logo=fastapi)](https://fastapi.tiangolo.com)
[![Qdrant](https://img.shields.io/badge/Qdrant-Vector_DB-DC244C?logo=qdrant)](https://qdrant.tech)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4-412991?logo=openai)](https://openai.com)
[![uv](https://img.shields.io/badge/uv-Package_Manager-DE5FE9?logo=astral)](https://docs.astral.sh/uv/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

<p align="center">
  <i>ğŸ¯ Hybrid Vector Search â€¢ ğŸ” Relevance Evaluation â€¢ ğŸŒ Web Search Fallback â€¢ âœ¨ Answer Validation</i>
</p>

[Features](#-features) â€¢ [Quick Start](#-quick-start) â€¢ [Architecture](#-architecture) â€¢ [API](#-api-endpoints) â€¢ [Workflows](#-workflows)

<br>

```ascii
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                              â•‘
â•‘   ğŸ“š Upload Documents  â†’  ğŸ” Hybrid Search  â†’  ğŸ¤– LLM Gen    â•‘
â•‘                                                              â•‘
â•‘   âœ… Hybrid Search: Dense + Sparse + RRF Fusion             â•‘
â•‘   âœ… CRAG: Adaptive Web Search Based on Relevance           â•‘
â•‘   âœ… Self-Reflective: Iterative Answer Grounding            â•‘
â•‘   âœ… Both: Combined for Maximum Quality                     â•‘
â•‘                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

</div>

---

## âœ¨ Features

<table>
<tr>
<td width="50%">

### ğŸ¯ **CRAG Mode**
- ğŸ“Š **LLM-based relevance evaluation**
- ğŸŒ **Adaptive web search** (Tavily)
- ğŸ”€ **Smart routing** (relevant/ambiguous/irrelevant)
- âš¡ **Real-time data access**

</td>
<td width="50%">

### ğŸ” **Self-Reflective Mode**
- âœ… **Answer grounding validation**
- ğŸ”„ **Iterative query refinement**
- ğŸ¯ **Hallucination detection**
- ğŸ“ **Source attribution**

</td>
</tr>
<tr>
<td width="50%">

### ğŸš€ **Both Mode**
- ğŸ”® **CRAG + Self-Reflective combined**
- ğŸ† **Maximum quality assurance**
- ğŸŒ **Web search preserved across iterations**
- ğŸ“ **Production-ready accuracy**

</td>
<td width="50%">

### ğŸ› ï¸ **Core Capabilities**
- ğŸ” **Hybrid Search**: Dense + Sparse + RRF
- ğŸ“„ **Multi-format support** (PDF, MD, TXT, JSON)
- ğŸ§© **HybridChunker** (Docling integration)
- ğŸ—„ï¸ **Qdrant dual vector storage**
- ğŸ”§ **Optional HYDE + Reranking**

</td>
</tr>
</table>

---

## ğŸ” Hybrid Search Modes

This system implements **true hybrid search** using Qdrant's dual vector system:

| Mode | Description | Best For |
|------|-------------|----------|
| **ğŸ¯ Dense** | Semantic search using OpenAI embeddings | Conceptual queries, synonyms |
| **ğŸ“ Sparse** | BM25 keyword search with IDF weighting | Exact terms, technical jargon |
| **âš¡ Hybrid** | RRF fusion of dense + sparse (default) | Best overall accuracy |

**Key Features:**
- **Dual Vector Indexing**: Every document gets both dense (1536-dim) and sparse (BM25) vectors
- **RRF Fusion**: Reciprocal Rank Fusion combines rankings from both search methods
- **Automatic Tokenization**: 50+ stop words filtered, term frequency analysis
- **Compatible**: Works with all RAG modes, HYDE, and reranking

---

## ğŸš€ Quick Start

### Prerequisites

```bash
âœ… Python 3.12+
âœ… Docker (for Qdrant)
âœ… OpenAI API Key
âœ… Tavily API Key (for CRAG mode)
```

### Installation in 3 Steps

```bash
# 1ï¸âƒ£ Install uv (ultra-fast package manager)
curl -LsSf https://astral.sh/uv/install.sh | sh

# 2ï¸âƒ£ Clone and setup
git clone <repo-url>
cd corrective_self_reflective_rag
cp .env.example .env
# Edit .env with your API keys

# 3ï¸âƒ£ Start services
docker run -p 6333:6333 qdrant/qdrant  # Terminal 1
uv run uvicorn app.main:app --reload   # Terminal 2
```

ğŸ‰ **Done!** API running at http://localhost:8000 â€¢ Docs at http://localhost:8000/docs

---

## ğŸ—ï¸ Architecture

<div align="center">

```mermaid
graph LR
    A[ğŸ“¤ User Query] --> B{Mode?}
    B -->|Standard| C[ğŸ” Vector Search]
    B -->|CRAG| D[ğŸ“Š Relevance Check]
    B -->|Self-Reflective| E[ğŸ”„ Iteration Loop]
    B -->|Both| F[ğŸ”® CRAG + Self-Reflective]

    D -->|Irrelevant| G[ğŸŒ Web Search]
    D -->|Relevant| H[ğŸ“š Use Docs]

    E --> I[âœ… Grounding Check]
    I -->|Score < 0.8| J[ğŸ”„ Refine Query]

    C --> K[ğŸ¤– Generate Answer]
    G --> K
    H --> K

    style A fill:#e1f5e1
    style K fill:#e1f5e1
    style D fill:#fff4e6
    style E fill:#e6f3ff
    style F fill:#ffe6f3
```

</div>

### ğŸ¯ RAG Mode Comparison

| Feature | Standard | CRAG | Self-Reflective | Both |
|---------|----------|------|-----------------|------|
| **Hybrid Search** | âœ… | âœ… | âœ… | âœ… |
| **Web Search** | âŒ | âœ… | âŒ | âœ… |
| **Quality Validation** | âŒ | âŒ | âœ… | âœ… |
| **Query Refinement** | âŒ | âŒ | âœ… | âœ… |
| **Latency** | ğŸŸ¢ Fast | ğŸŸ¡ Medium | ğŸŸ  Slow | ğŸ”´ Slowest |
| **Accuracy** | ğŸŸ¡ Good | ğŸŸ¢ Better | ğŸŸ¢ Better | ğŸŸ¢ Best |
| **Use Case** | Simple Q&A | Current data | High accuracy | Production |

---

## ğŸ“¡ API Endpoints

### 1ï¸âƒ£ Upload Document

```bash
curl -X POST "http://localhost:8000/upload/" \
  -F "file=@document.pdf"
```

**Response:** âœ… Document processed â†’ Chunks stored in Qdrant

### 2ï¸âƒ£ Query (CRAG Mode)

```bash
curl -X POST "http://localhost:8000/query/" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What is the weather today in New Delhi?",
    "mode": "crag",
    "top_k": 5
  }'
```

**Returns:** Answer + Relevance Evaluation + Web Search Results (if triggered)

### 3ï¸âƒ£ Query (Self-Reflective Mode)

```bash
curl -X POST "http://localhost:8000/query/" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Explain the methodology in detail",
    "mode": "self_reflective",
    "top_k": 5
  }'
```

**Returns:** Refined Answer + Reflection Score + Iteration Count

### 4ï¸âƒ£ Query with Hybrid Search (Recommended)

```bash
curl -X POST "http://localhost:8000/query/" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What are the latest AI developments?",
    "mode": "both",
    "search_mode": "hybrid",
    "top_k": 5,
    "enable_hyde": true,
    "enable_reranking": true
  }'
```

**Returns:** Maximum quality answer with Hybrid Search + CRAG + Self-Reflective

**Search Mode Options:**
- `"dense"` - Semantic search only
- `"sparse"` - Keyword search only (BM25)
- `"hybrid"` - RRF fusion (default, recommended)

### 5ï¸âƒ£ Compare All Modes

```bash
curl "http://localhost:8000/query/compare?query=Your%20question&top_k=5"
```

**Returns:** Side-by-side comparison of Standard, CRAG, and Self-Reflective

---

## ğŸ“Š Workflows

Detailed Mermaid diagrams available in [`workflows/`](./workflows/):

- ğŸ—ï¸ **[Project Architecture](./workflows/project_architecture.md)** - Complete system design
- ğŸ”„ **[CRAG Mode](./workflows/crag_mode.md)** - Adaptive web search workflow
- ğŸ” **[Self-Reflective Mode](./workflows/self_reflective_mode.md)** - Grounding validation workflow
- ğŸš€ **[Both Mode](./workflows/both_mode.md)** - Combined pipeline workflow

---

## âš™ï¸ Configuration

Key settings in `.env`:

```bash
# ğŸ¤– LLM Configuration
OPENAI_API_KEY=sk-...
LLM_MODEL=gpt-4o-mini

# ğŸ” Hybrid Search Settings
HYBRID_SEARCH_ENABLED=true        # Enable hybrid search
SPARSE_VECTOR_ENABLED=true        # Enable sparse vectors (BM25)
RRF_K=60                          # RRF fusion parameter

# ğŸ“Š CRAG Settings
CRAG_RELEVANCE_THRESHOLD=0.7      # Relevant if score â‰¥ 0.7
CRAG_AMBIGUOUS_THRESHOLD=0.5      # Irrelevant if score < 0.5
TAVILY_API_KEY=tvly-...           # Web search

# âœ… Self-Reflective Settings
REFLECTION_MIN_SCORE=0.8          # Accept if grounding â‰¥ 0.8
MAX_REFLECTION_RETRIES=2          # Max refinement iterations

# ğŸ—„ï¸ Vector Database
QDRANT_URL=http://localhost:6333
QDRANT_COLLECTION_NAME=crag_documents

# ğŸš€ Optional Features
HYDE_ENABLED_BY_DEFAULT=false     # Query expansion
RERANKING_ENABLED_BY_DEFAULT=false
RERANKER_BACKEND=local            # or 'voyage'
```

---

## ğŸ§ª Testing

```bash
# Run all tests
uv run pytest -v

# Test specific mode
uv run python test_features.py

# Test backend switching
uv run python test_backends.py

# With coverage
uv run pytest --cov=app --cov-report=html
```

---

## ğŸ“ Project Structure

```
corrective_self_reflective_rag/
â”œâ”€â”€ ğŸ“± app/
â”‚   â”œâ”€â”€ api/              # ğŸš€ FastAPI endpoints
â”‚   â”œâ”€â”€ core/             # ğŸ”§ Core business logic
â”‚   â”œâ”€â”€ services/         # ğŸ› ï¸ Service implementations
â”‚   â”œâ”€â”€ config.py         # âš™ï¸ Settings
â”‚   â””â”€â”€ models.py         # ğŸ“Š Pydantic schemas
â”œâ”€â”€ ğŸ“š workflows/         # ğŸ“– Architecture docs + Mermaid diagrams
â”œâ”€â”€ ğŸ“‚ uploads/           # ğŸ“„ Document storage
â”œâ”€â”€ ğŸ§ª tests/            # âœ… Test suite
â”œâ”€â”€ .env.example          # ğŸ” Config template
â”œâ”€â”€ pyproject.toml        # ğŸ“¦ Dependencies
â””â”€â”€ CLAUDE.md            # ğŸ“˜ Full documentation
```

---

## ğŸ“ Learn More

### ğŸ“š Research Papers

- **CRAG**: [Corrective Retrieval Augmented Generation](https://arxiv.org/abs/2401.15884)
- **Self-Reflective RAG**: [Self-RAG: Learning to Retrieve, Generate, and Critique](https://arxiv.org/abs/2310.11511)

### ğŸ› ï¸ Technology Stack

- **Framework**: [FastAPI](https://fastapi.tiangolo.com) - Modern Python API framework
- **Vector DB**: [Qdrant](https://qdrant.tech) - High-performance vector search
- **LLM**: [OpenAI GPT-4](https://openai.com) - Language model
- **Document Processing**: [Docling](https://github.com/DS4SD/docling) - PDF/MD parsing
- **Web Search**: [Tavily](https://tavily.com) - AI search API
- **Package Manager**: [uv](https://docs.astral.sh/uv/) - Ultra-fast Python package manager

---

## ğŸ¤ Contributing

Contributions welcome! Please check out:
- ğŸ“˜ [CLAUDE.md](./CLAUDE.md) - Complete development guide
- ğŸ—ï¸ [Architecture Docs](./workflows/project_architecture.md) - System design
- âœ… [Testing Guide](./workflows/README.md) - Test strategy

---

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) for details

---

## ğŸ™ Acknowledgments

Built with inspiration from cutting-edge RAG research and powered by:
- ğŸ¤– OpenAI for LLM capabilities
- ğŸ—„ï¸ Qdrant for vector search excellence
- ğŸ“š Docling for document intelligence
- ğŸŒ Tavily for web search integration

---

<div align="center">

### âš¡ Powered by [uv](https://docs.astral.sh/uv/) - The Fast Python Package Manager

**Built for demonstrating advanced RAG patterns in production-ready architecture**

ğŸŒŸ **Star this repo if you find it useful!** ğŸŒŸ

[Report Bug](https://github.com/your-repo/issues) â€¢ [Request Feature](https://github.com/your-repo/issues) â€¢ [Documentation](./CLAUDE.md)

</div>
